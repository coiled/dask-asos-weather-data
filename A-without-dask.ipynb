{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f6545-d46b-4d1b-aa60-9261b3938be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP, error_perm, error_temp\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "from cloudside.asos import MetarParser, _find_reset_time, _process_precip, FIVEMIN\n",
    "\n",
    "\n",
    "EMAIL = \"paul+faa@coiled.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21bd58-3ecc-4f44-ba4a-7efe968d3352",
   "metadata": {},
   "source": [
    "## A - Without Dask\n",
    "\n",
    "* Function to list all of the files available for a given station-year (e.g., 2020 at KPDX)\n",
    "* Function to transfer individual files from FTP to local file system\n",
    "* Function to parse the local file, converting rainfall to instanteous values from cumulative values that reset hourly, and creating a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e870a3-ec93-403b-88fa-c797893d4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(station, year):\n",
    "    with FTP(\"ftp.ncei.noaa.gov\") as ftp:\n",
    "        ftp.login(passwd=EMAIL)\n",
    "        try:\n",
    "            uri = f\"6/pub/data/asos-fivemin/401-{year}/*{station}*\"\n",
    "            dat_files = ftp.nlst(uri)\n",
    "        except error_perm as e:\n",
    "            print(e)\n",
    "    return dat_files\n",
    "\n",
    "\n",
    "def transfer_locally(dat_in, dat_out):\n",
    "    p_in = Path(dat_in)\n",
    "    p_out = Path(dat_out)\n",
    "    # don't try to transfer something you already have locally\n",
    "    if not p_out.exists() or (p_out.stat().st_size == 0):\n",
    "        try:\n",
    "            with FTP(\"ftp.ncei.noaa.gov\") as ftp, p_out.open(\"w\") as outfile:\n",
    "                ftp.login(passwd=EMAIL)\n",
    "                ftp.retrlines(\n",
    "                    f\"RETR {dat_in}\",\n",
    "                    lambda x: outfile.write(x + \"\\n\")\n",
    "                )\n",
    "            file_size = p_out.stat().st_size\n",
    "            status = \"transferred\"\n",
    "\n",
    "        except Exception as e:\n",
    "            file_size = None\n",
    "            status = str(e)\n",
    "    else:\n",
    "        file_size = p_out.stat().st_size\n",
    "        status = \"exists already\"\n",
    "\n",
    "    return {\n",
    "        \"source\": p_in,\n",
    "        \"file\": p_out,\n",
    "        \"status\": status,\n",
    "        \"size\": file_size\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_local(dat_local):\n",
    "    p = Path(dat_local)\n",
    "    with p.open(\"r\") as datafile:\n",
    "        data = [\n",
    "            MetarParser(line, strict=False).asos_dict(null_sky_as=None)\n",
    "            for line in datafile\n",
    "        ]\n",
    "\n",
    "    df = (\n",
    "        pandas.DataFrame(data)\n",
    "            .groupby(\"datetime\").last()\n",
    "            .sort_index()\n",
    "            .resample(FIVEMIN).asfreq()\n",
    "    )\n",
    "    rt = _find_reset_time(df[\"raw_precipitation\"])\n",
    "    precip = _process_precip(df, rt, \"raw_precipitation\")\n",
    "    return df.assign(precip=precip).set_index(\"station\", append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dfbd91-406e-49c3-ba14-00277a86f2ed",
   "metadata": {},
   "source": [
    "## Execute everything\n",
    "\n",
    "* Loop through years and stations to get a comprehensive list of files on the FTP\n",
    "* Loop through the files and transfer locally\n",
    "* Loop through the local files, parse, convert to dataframe\n",
    "* Concatenate all of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4547743-2b33-435a-a5de-c026ce0241cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [\"KATL\", \"KPDX\"]\n",
    "years = list(range(2020, 2022))\n",
    "\n",
    "files = []\n",
    "pbar = tqdm(list(product(stations, years)))\n",
    "for station, year in pbar:\n",
    "    pbar.set_description(f\"finding {year} files for {station}: \")\n",
    "    files.extend(get_all_files(station, year))\n",
    "\n",
    "status = []\n",
    "pbar = tqdm(files)\n",
    "folder_out = Path(\"data\", \"serial\")\n",
    "folder_out.mkdir(parents=True, exist_ok=True)\n",
    "for dat_in in pbar:\n",
    "    pbar.set_description(f\"transferring {dat_in}\")\n",
    "    name = Path(dat_in).name\n",
    "    dat_out = folder_out.joinpath(name)\n",
    "    dat_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    status.append(transfer_locally(dat_in, dat_out))\n",
    "\n",
    "pbar = tqdm(status)\n",
    "list_of_dataframes = []\n",
    "for s in pbar:\n",
    "    if s[\"size\"]:\n",
    "        pbar.set_description(f\"parsing {s['file']}\")\n",
    "        list_of_dataframes.append(parse_local(s[\"file\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7c107-aaf3-4f21-b5ac-f65938ab7c96",
   "metadata": {},
   "source": [
    "## Quick summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898ffc1-b858-4aa2-b90c-6a948d5b3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.concat(list_of_dataframes, ignore_index=False)\n",
    "(\n",
    "    data.loc[lambda df: df[\"temperature\"].gt(-25)]\n",
    "        .groupby(level=\"station\")[[\"temperature\", \"wind_speed\"]]\n",
    "        .agg([\"min\", \"max\"])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
